/**
 * VoiceInterviewUI Component
 * 
 * This component provides the voice-based interview interface with:
 * - Current question displayed prominently at the top
 * - Single centered voice recording interface
 * - Feedback display (assessment + coaching) after each question
 * - Continue button to proceed to next question
 * - Error handling and accessibility features
 * - Integration with live interview backend procedures
 */

'use client';

import React, { useState, useRef, useEffect } from 'react';
import Timer from '~/components/UI/Timer';
// Removed direct Gemini import for security - API keys must stay server-side
import { useRouter } from 'next/navigation';
import { api } from '~/trpc/react';

interface ConversationMessage {
  role: 'ai' | 'user';
  content: string;
  timestamp: string;
}

interface VoiceInterviewUIProps {
  sessionData: {
    sessionId: string;
    isActive: boolean;
    personaId: string;
    currentQuestion: string;
    keyPoints?: string[];
    conversationHistory: ConversationMessage[];
    questionNumber: number;
    timeRemaining: number;
    startTime: Date | null;
  };
  currentQuestion: string;
  keyPoints?: string[];
  onPause: () => Promise<void>;
  onEnd: () => Promise<void>;
}

interface FeedbackData {
  assessment: string;
  coaching: string;
}

type RecordingState = 'idle' | 'recording' | 'stopped' | 'processing' | 'feedback' | 'error';

export default function VoiceInterviewUI({
  sessionData,
  currentQuestion,
  keyPoints,
  onPause,
  onEnd,
}: VoiceInterviewUIProps) {
  const [recordingState, setRecordingState] = useState<RecordingState>('idle');
  const [recordingDuration, setRecordingDuration] = useState(0);
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [mediaRecorder, setMediaRecorder] = useState<MediaRecorder | null>(null);
  const [feedback, setFeedback] = useState<FeedbackData | null>(null);
  const [transcript, setTranscript] = useState<string>('');
  const router = useRouter();
  
  const durationIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const [questionText, setQuestionText] = useState(currentQuestion);

  // tRPC mutation for ending question and getting feedback
  const endQuestionMutation = api.session.endQuestion.useMutation({
    onSuccess: (data) => {
      setFeedback(data);
      setRecordingState('feedback');
    },
    onError: (error) => {
      console.error('Error ending question:', error);
      setError('Failed to process your answer. Please try again.');
      setRecordingState('error');
    },
  });



  // Auto-start recording on mount to enable hands-free flow (Phase-2 requirement)
  useEffect(() => {
    if (recordingState === 'idle') {
      // Fire and forget â€“ errors are already handled inside startRecording
      // eslint-disable-next-line @typescript-eslint/no-floating-promises
      startRecording();
    }
    // We intentionally run this effect only once on mount.
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  const formatTime = (seconds: number): string => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  const startRecording = async () => {
    try {
      setError(null);
      setFeedback(null); // Clear previous feedback
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const recorder = new MediaRecorder(stream);
      const chunks: Blob[] = [];

      recorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunks.push(event.data);
        }
      };

      recorder.onstop = () => {
        const blob = new Blob(chunks, { type: 'audio/wav' });
        setAudioBlob(blob);
        setRecordingState('stopped');
        stream.getTracks().forEach(track => track.stop());
      };

      recorder.start();
      setMediaRecorder(recorder);
      setRecordingState('recording');
      setRecordingDuration(0);

      // Start duration timer
      durationIntervalRef.current = setInterval(() => {
        setRecordingDuration(prev => prev + 1);
      }, 1000);

    } catch (err) {
      setError('Microphone access denied. Please enable microphone permission and try again.');
      setRecordingState('error');
    }
  };

  const stopRecording = () => {
    if (mediaRecorder && recordingState === 'recording') {
      mediaRecorder.stop();
      if (durationIntervalRef.current) {
        clearInterval(durationIntervalRef.current);
        durationIntervalRef.current = null;
      }
      // Note: No longer need to signal Gemini Live since we're using direct audio upload
    }
  };

  const handleEndQuestion = async () => {
    if (!audioBlob) {
      setError('No audio recorded. Please try recording again.');
      setRecordingState('error');
      return;
    }
    
    try {
      setRecordingState('processing');
      // For now, simulate transcript from audio blob (future: server-side transcription)
      const simulatedTranscript = `[Audio response recorded - ${Math.round(audioBlob.size / 1024)}KB]`;
      
      await endQuestionMutation.mutateAsync({
        sessionId: sessionData.sessionId,
        questionText: questionText,
        transcript: simulatedTranscript,
      });
      // State will be updated to 'feedback' via onSuccess callback
    } catch (err) {
      // Error handling is done in the mutation onError callback
      console.error('Error in handleEndQuestion:', err);
    }
  };

  const handleRetryRecording = () => {
    setAudioBlob(null);
    setTranscript('');
    setRecordingState('idle');
    setRecordingDuration(0);
    setError(null);
    setFeedback(null);
  };

  const handleContinue = () => {
    // Reset for next question
    setFeedback(null);
    setTranscript('');
    setAudioBlob(null);
    setRecordingState('idle');
    setRecordingDuration(0);
    // This should trigger opening a new socket for the next question
    // For now, we'll restart the recording
    void startRecording();
  };

  const getStatusMessage = (): string => {
    switch (recordingState) {
      case 'recording':
        return 'Recording your answer...';
      case 'stopped':
        return 'Recording complete. Ready to submit.';
      case 'processing':
        return 'Processing your answer...';
      case 'feedback':
        return 'Feedback ready!';
      case 'error':
        return 'Recording error occurred.';
      default:
        return 'Click to Start Interview';
    }
  };

  const getRecordButtonLabel = (): string => {
    switch (recordingState) {
      case 'recording':
        return 'Stop recording';
      case 'stopped':
        return 'Record new answer';
      case 'processing':
        return 'Processing...';
      case 'feedback':
        return 'Recording complete';
      case 'error':
        return 'Retry recording';
      default:
        return 'Start recording';
    }
  };

  return (
    <div
      data-testid="voice-interview-ui"
      className="flex flex-col h-full bg-white dark:bg-slate-900 rounded-lg shadow-sm border border-gray-200 dark:border-gray-600"
    >
      {/* Current Question Section - Top */}
      <div className="flex-shrink-0 bg-gradient-to-r from-green-50 to-emerald-50 dark:from-slate-800 dark:to-slate-700 border-b border-gray-200 dark:border-gray-600 p-6">
        <div className="w-full flex gap-6">
          {/* Questions and Guidance Container */}
          <div className="flex-1">
            <div className="flex items-center gap-3 mb-4">
              <div className="w-2 h-2 bg-green-500 rounded-full animate-pulse"></div>
              <span className="text-sm font-medium text-gray-600 dark:text-gray-300">
                Current Question:
              </span>
            </div>
            
            <h2 data-testid="current-question-text" className="text-xl font-semibold text-gray-900 dark:text-white leading-relaxed mb-4 p-4 bg-gray-50/30 dark:bg-slate-800/30 rounded-lg">
              {questionText || 'Loading next question...'}
            </h2>
            
            {/* Voice Guidance */}
            <div className="bg-white/60 dark:bg-slate-800/60 rounded-lg p-4 border border-green-100 dark:border-gray-600">
              <div className="flex items-start gap-3">
                <div className="w-5 h-5 bg-green-100 dark:bg-green-900 rounded-full flex items-center justify-center flex-shrink-0 mt-0.5">
                  <span className="text-green-600 dark:text-green-400 text-xs font-semibold">ðŸŽ¤</span>
                </div>
                <div className="text-sm text-gray-700 dark:text-gray-300">
                  <strong className="text-green-900 dark:text-green-400">Key points:</strong>
                  <ul className="list-disc list-inside mt-1 space-y-1">
                    {keyPoints && keyPoints.length > 0 ? (
                      keyPoints.map((point, index) => (
                        <li key={index}>{point}</li>
                      ))
                    ) : (
                      <>
                        <li>Focus on your specific role and contributions</li>
                        <li>Highlight technologies and tools you used</li>
                        <li>Discuss challenges faced and how you overcame them</li>
                      </>
                    )}
                  </ul>
                </div>
              </div>
            </div>
          </div>

          {/* Timer Container */}
          <div className="flex-shrink-0 flex items-center">
            {sessionData.startTime && <Timer />}
          </div>
        </div>
      </div>

      {/* Main Content Area - Single Voice Component */}
      <div className="flex-1 flex items-center justify-center bg-gray-50/30 dark:bg-slate-800/30 p-8">
        <div className="flex flex-col items-center justify-center text-center max-w-lg">
          {/* Recording Status */}
          <div role="status" aria-live="polite" className="flex flex-col items-center justify-center">
            <div className={`relative w-40 h-40 rounded-full flex items-center justify-center mb-6 transition-all duration-300 border-4 ${
              recordingState === 'recording'
                ? 'bg-red-50 dark:bg-red-900/20 border-red-500 dark:border-red-400 shadow-lg animate-pulse' 
                : recordingState === 'error'
                ? 'bg-orange-50 dark:bg-orange-900/20 border-orange-500 dark:border-orange-400'
                : recordingState === 'stopped'
                ? 'bg-blue-50 dark:bg-blue-900/20 border-blue-500 dark:border-blue-400'
                : 'bg-gray-50 dark:bg-gray-800 border-gray-300 dark:border-gray-600 hover:border-green-500 dark:hover:border-green-400 shadow-md hover:shadow-lg'
            }`}>
              <button
                data-testid="record-toggle"
                onClick={recordingState === 'recording' ? stopRecording : startRecording}
                disabled={recordingState === 'processing' || recordingState === 'feedback'}
                aria-label={getRecordButtonLabel()}
                className="w-full h-full flex items-center justify-center disabled:opacity-50 relative"
              >
                {/* Person Icon */}
                <svg 
                  className={`w-20 h-20 transition-colors ${
                    recordingState === 'recording'
                      ? 'text-red-500 dark:text-red-400' 
                      : recordingState === 'error'
                      ? 'text-orange-500 dark:text-orange-400'
                      : recordingState === 'stopped'
                      ? 'text-blue-500 dark:text-blue-400'
                      : 'text-gray-400 dark:text-gray-500 hover:text-green-500 dark:hover:text-green-400'
                  }`} 
                  fill="none" 
                  stroke="currentColor" 
                  viewBox="0 0 24 24"
                >
                  <path 
                    strokeLinecap="round" 
                    strokeLinejoin="round" 
                    strokeWidth={1.5}
                    d="M16 7a4 4 0 11-8 0 4 4 0 018 0zM12 14a7 7 0 00-7 7h14a7 7 0 00-7-7z" 
                  />
                </svg>
                
                {/* Recording indicator */}
                {recordingState === 'recording' && (
                  <div className="absolute -bottom-2 -right-2 w-6 h-6 bg-red-500 dark:bg-red-400 rounded-full flex items-center justify-center animate-pulse">
                    <div className="w-3 h-3 bg-white rounded-full"></div>
                  </div>
                )}
                
                {/* Microphone icon overlay for stopped state */}
                {recordingState === 'stopped' && (
                  <div className="absolute -bottom-2 -right-2 w-8 h-8 bg-blue-500 dark:bg-blue-400 rounded-full flex items-center justify-center">
                    <svg className="w-4 h-4 text-white" fill="currentColor" viewBox="0 0 24 24">
                      <path d="M12 14c1.66 0 2.99-1.34 2.99-3L15 5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm5.3-3c0 3-2.54 5.1-5.3 5.1S6.7 14 6.7 11H5c0 3.41 2.72 6.23 6 6.72V21h2v-3.28c3.28-.48 6-3.3 6-6.72h-1.7z"/>
                    </svg>
                  </div>
                )}
              </button>
            </div>
            
            <div className="text-xl font-medium text-gray-900 dark:text-white text-center">
              {getStatusMessage()}
            </div>
            
            {recordingState === 'recording' && (
              <div className="text-lg text-gray-600 dark:text-gray-400">
                Duration: {formatTime(recordingDuration)}
              </div>
            )}
          </div>

          {/* Error Display */}
          {error && (
            <div className="bg-red-50 dark:bg-red-900/20 border border-red-200 dark:border-red-600 rounded-lg p-4 mb-6">
              <div className="text-red-700 dark:text-red-400 text-sm">
                {error}
              </div>
            </div>
          )}

          {/* Action Buttons */}
          <div className="space-y-4">
            {recordingState === 'stopped' && audioBlob && (
              <div className="flex gap-4 justify-center">
                <button
                  onClick={handleEndQuestion}
                  disabled={recordingState !== 'stopped'}
                  className="px-8 py-4 bg-blue-600 hover:bg-blue-700 dark:bg-blue-500 dark:hover:bg-blue-600 text-white rounded-lg focus:ring-2 focus:ring-blue-500 disabled:opacity-50 disabled:cursor-not-allowed transition-colors font-medium text-lg"
                >
                  Submit Answer
                </button>
                <button
                  onClick={handleRetryRecording}
                  disabled={recordingState !== 'stopped'}
                  className="px-8 py-4 border border-gray-300 dark:border-gray-600 text-gray-700 dark:text-gray-300 rounded-lg hover:bg-gray-50 dark:hover:bg-slate-800 focus:ring-2 focus:ring-gray-500 disabled:opacity-50 transition-colors font-medium text-lg"
                >
                  Try Again
                </button>
              </div>
            )}

            {/* Feedback Display */}
            {recordingState === 'feedback' && feedback && (
              <div className="bg-green-50 dark:bg-green-900/20 border border-green-200 dark:border-green-600 rounded-lg p-6 space-y-4 max-w-2xl mx-auto">
                <h3 className="text-xl font-semibold text-green-800 dark:text-green-300">Feedback</h3>
                <div className="space-y-4 text-left">
                  <div>
                    <h4 className="font-medium text-green-700 dark:text-green-400 mb-2">Assessment:</h4>
                    <p className="text-green-600 dark:text-green-300">{feedback.assessment}</p>
                  </div>
                  <div>
                    <h4 className="font-medium text-green-700 dark:text-green-400 mb-2">Coaching:</h4>
                    <p className="text-green-600 dark:text-green-300">{feedback.coaching}</p>
                  </div>
                </div>
                <button
                  onClick={handleContinue}
                  className="px-8 py-4 bg-green-600 hover:bg-green-700 text-white rounded-lg focus:ring-2 focus:ring-green-500 transition-colors font-medium text-lg"
                >
                  Continue to Next Question
                </button>
              </div>
            )}

                         {recordingState === 'error' && (
               <button
                 onClick={() => window.location.href = `${window.location.pathname}?mode=text`}
                 className="px-6 py-2 text-gray-600 dark:text-gray-300 hover:text-gray-800 dark:hover:text-white text-sm border border-gray-300 dark:border-gray-600 rounded-lg hover:bg-gray-50 dark:hover:bg-slate-800 transition-colors"
               >
                 Switch to Text Mode
               </button>
             )}
          </div>

          {/* Processing Indicator */}
          {recordingState === 'processing' && (
            <div className="mt-8 bg-blue-50 dark:bg-blue-900/20 border border-blue-200 dark:border-blue-600 rounded-lg p-6">
              <div className="flex items-center justify-center gap-3 text-blue-700 dark:text-blue-400">
                <div className="flex gap-1">
                  <div className="w-3 h-3 bg-blue-500 dark:bg-blue-400 rounded-full animate-pulse"></div>
                  <div className="w-3 h-3 bg-blue-500 dark:bg-blue-400 rounded-full animate-pulse" style={{ animationDelay: '0.2s' }}></div>
                  <div className="w-3 h-3 bg-blue-500 dark:bg-blue-400 rounded-full animate-pulse" style={{ animationDelay: '0.4s' }}></div>
                </div>
                <span className="font-medium text-lg">Processing your answer...</span>
              </div>
            </div>
          )}

          {/* socket ready indicator for tests - simplified since no Gemini Live */}
          <div data-testid="socket-open" className="sr-only" />
        </div>
      </div>

      {/* Controls Section - Bottom */}
      <div className="flex-shrink-0 bg-white dark:bg-slate-900 border-t border-gray-200 dark:border-gray-600 p-6">
        <div className="w-full">
          <div className="flex justify-between items-center">
            <div className="text-sm text-gray-500 dark:text-gray-400">
              Voice mode with real-time transcription. Speak naturally and clearly for best results.
            </div>
            <div className="flex gap-3">
              <button
                data-testid="next-question-btn"
                onClick={handleContinue}
                className="px-4 py-2 bg-green-600 hover:bg-green-700 text-white text-sm font-medium rounded-lg transition-colors"
              >
                Next Question
              </button>
              <button
                data-testid="end-interview-btn"
                onClick={async () => {
                  stopRecording();
                  // Note: No longer need to close Gemini Live session since we're using direct audio upload
                  router.push(`/sessions/${sessionData.sessionId}/report`);
                }}
                className="px-4 py-2 text-red-600 dark:text-red-400 hover:text-red-700 dark:hover:text-red-300 text-sm font-medium hover:bg-red-50 dark:hover:bg-red-900/20 rounded-lg transition-colors"
              >
                End Interview
              </button>
            </div>
          </div>
        </div>
      </div>
    </div>
  );
} 